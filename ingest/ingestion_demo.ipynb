{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loved-christianity",
   "metadata": {},
   "source": [
    "## Python Ingestion\n",
    "The purpose of this notebook is to demonstrate how to use the demo Python ingestion code, as well as discuss possible next steps as we work to build something that is ready to show clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-iceland",
   "metadata": {},
   "source": [
    "### Overview\n",
    "My idea is to split the overall task of data ingestion into two processes. The first process is handled by `DataParsers`, which are responsible for locating files containing data to ingest and turning that data into `Streams`. `Streams` contain arrays of timestamps and values, as well as metadata (collection name, tags, annotations). `Stream` objects are passed to `DataIngestors`, which are responsible for mapping `Stream` objects to BTrDB streams (or creating a new stream if it doesn't exist yet), and inserting points, 50k at a time.\n",
    "\n",
    "This example uses `CSVParser`, which is an implementation of the `DataParser` interface. In my opinion, most ingestions will require the user to write a new `DataParser` class, because it will contain bespoke code to find and parse files that will almost definitely have unique formats/oddities. Writing a valid `DataParser` will be the responsibility of the user, whereas the `DataIngestor` should be suitable for all use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "operational-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import btrdb\n",
    "from csv_parser import CSVParser\n",
    "from ingest import DataIngestor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "previous-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6480000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate CSVParser with path for stream data and collection prefix\n",
    "cp = CSVParser(fpath=\"test_csvs/\", collection_prefix=\"test_ingest\")\n",
    "\n",
    "# locate files and calculate total number of points\n",
    "files = cp.collect_files(total=True)\n",
    "total_points = sum([f.count for f in files])\n",
    "total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hourly-heaven",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6480060it [04:10, 28483.51it/s]                             "
     ]
    }
   ],
   "source": [
    "# Connect to BTrDB, instantiate ingestor and insert data\n",
    "conn = btrdb.connect(profile=os.environ[\"BTRDB_PROFILE\"])\n",
    "\n",
    "ingestor = DataIngestor(conn, total_points=total_points)\n",
    "for streams in cp.create_streams(files):\n",
    "    ingestor.ingest(streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-chest",
   "metadata": {},
   "source": [
    "## Potential Next Steps\n",
    "Here are a few ideas that I had to improve this tool and make it user ready:\n",
    "* It would be really nice to set this up in a producer/consumer pattern where we have multiple `DataParsers` parsing files into `Stream` objects and passing those to `DataIngestors` via a queue or some sort of shared storage\n",
    "* We likely need to make this compatible with s3\n",
    "* We may want to provide a few strategies to help clients match metadata with streams. I took a very simple approach here, but it might be nice to allow clients to provide a yaml/json file specifying their metadata schema. Importman does this but it's a bit confusing how it works for newbies, so we'll need to thoroughly document whatever solution we come up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-accident",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
